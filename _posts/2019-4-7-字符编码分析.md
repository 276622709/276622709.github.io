---
layout: post
title: 字符编码分析
date: 2019-4-7
author: ZMY
header-img: img/character_analyze.jpg
tags:
    - 字符编码分析
---

## <img class="original" src='https://raw.githubusercontent.com/276622709/276622709.github.io/master/img/original.png'> 字符编码分析

    字符编码一直是个头疼的问题，通过对网上关于字符编码资料的查看与理解，现将自己的理解归纳如下（仅个人理解)。   
&nbsp;&nbsp;计算机中能识别的东西只有高低电平(高低电压)，电路由各种继电器组成，高低电平的变化，会导致继电器的通断，而二进制0和1正好可以反映继电器的  
两种状态通和断（高低电平），因此人们将计算机能识别的机器语言人为的定义为0和1。  
&nbsp;&nbsp;计算机最开始是老美发明的，用的是ascii编码，就是全英文这种，完全支持他们的键盘。无论是输入到内存还是保存到硬盘，中间涉及到的编码都是ascii编码后的二进制编码，ascii一共127位即7个二进制数即可搞定，01000001即是字母A在电脑里的数值，由A编译成01000001    
&nbsp;&nbsp;后来各个国家都用计算机，每个国家就都有了自己的编码系统，中国的如GBK,GB2312，GBK18030,台湾BIG5，日本Shift_JIS等编码陆续出现  
&nbsp;&nbsp;这样就带来一个问题，日本编码的文件怎么拿到中国电脑上呈现出来呢？  
&nbsp;&nbsp;再后来为了统一各国的编码就出现了unicode（万国码），各个国家的文字在unicode中都能找到，但是由于unicode默认使用2个字节去存储一个字符，这样当英文输入比较多的时候，比如代码文件,保存到磁盘或者在互联网中传输的时候占用的空间就比较大，是正常ascii编码的二倍。为了节省空间又提出了UTF-8编码，对于英文字符编码:1字节;汉字:2-4字节不等。以后规定在内存中用unicode编码，保存在文件中或打包成二进制文件在互联网中传输时候，采用其他编码方式(如UTF-8等)  
   
&nbsp;&nbsp;这里说一下由键盘到屏幕呈现，字符的转换过程  
&nbsp;&nbsp;键盘输入字符a，按完a后，继电器通断导致电压的变化会转换几个二进制，这里假设为0001，触发中断，中断处理程序（一般会调用键盘驱动程序去读取这个扫描码），通过这个扫描码，对应扫描码和ASCII转换表，转换成ASCII编码，如果有输入法软件，通过输入法软件转换成内码(即字符编码(按照什么方式编码取决于系统默认encoding.default值))，在内存中通过page code表由操作系统将字符编码转换成unicode码,通过unicode表找到矢量图，呈现出来  
&nbsp;&nbsp;流程如下所示  
  用户---汉字输入码---键盘---键盘扫描码---BIOS键盘驱动程序----ASCII码----(（有的话）汉字输入软件----汉字内码)----unicode码-----矢量图----显卡呈现  
